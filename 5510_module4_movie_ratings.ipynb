{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32e45eb6bcc8c7d1db2d846fc120d426",
     "grade": false,
     "grade_id": "cell-e212d9fd41f03b18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Module 4 - matrix factorization technique(s) to predict ratings\n",
    "\n",
    "Limitation(s) of sklearn’s non-negative matrix factorization library.\n",
    "\n",
    "Please mark the sections of your notebook as 1 and 2 so that graders can follow along.\n",
    "\n",
    "1. Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE. You should use sklearn library. [10 pts] Make sure that your notebook includes the following:\n",
    "* use's sklearn's non-negative matrix factorization\n",
    "* notebook shows the RMSE with an analysis of what that RMSE means\n",
    "\n",
    "2. Discuss the results and why they did not work well compared to simple baseline or similarity-based methods we’ve done in Module 3. Can you suggest a way(s) to fix it? [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "069f66d81507ea520c1fe5098352b437",
     "grade": false,
     "grade_id": "cell-ea989c7a4eb25b70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2025-09-24T17:41:14.450392Z",
     "start_time": "2025-09-24T17:41:13.022628Z"
    }
   },
   "source": [
    "from dataclasses import asdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, csr_matrix, diags\n",
    "from scipy.spatial.distance import jaccard, cosine, pdist, squareform\n",
    "from collections import namedtuple\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pytest import approx"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup - From Module 3"
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdeafa5886528c497f33ffde32d9b7bb",
     "grade": false,
     "grade_id": "cell-476e59a408937946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2025-09-24T17:41:14.634613Z",
     "start_time": "2025-09-24T17:41:14.544741Z"
    }
   },
   "source": [
    "MV_users = pd.read_csv('data/users_m3.csv')\n",
    "MV_movies = pd.read_csv('data/movies_m3.csv')\n",
    "train = pd.read_csv('data/train_m3.csv')\n",
    "test = pd.read_csv('data/test_m3.csv')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdd5d6c687c352a1ea45cfed3c7380eb",
     "grade": false,
     "grade_id": "cell-749c77774f53cfe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2025-09-24T17:41:14.643898Z",
     "start_time": "2025-09-24T17:41:14.639786Z"
    }
   },
   "source": [
    "\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "\n",
    "data = Data(MV_users, MV_movies, train, test)\n",
    "# Creating Sample test data\n",
    "np.random.seed(42)\n",
    "sample_train = train[:30000]\n",
    "sample_test = test[:30000]\n",
    "\n",
    "sample_MV_users = MV_users[(MV_users.uID.isin(sample_train.uID)) | (MV_users.uID.isin(sample_test.uID))]\n",
    "sample_MV_movies = MV_movies[(MV_movies.mID.isin(sample_train.mID)) | (MV_movies.mID.isin(sample_test.mID))]\n",
    "\n",
    "sample_data = Data(sample_MV_users, sample_MV_movies, sample_train, sample_test)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b203240e52b0e6e18286e3797922e639",
     "grade": false,
     "grade_id": "cell-f9c7ee3867550bb6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2025-09-24T17:41:14.660644Z",
     "start_time": "2025-09-24T17:41:14.648320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RecSys():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.allusers = list(self.data.users['uID'])\n",
    "        self.allmovies = list(self.data.movies['mID'])\n",
    "        self.genres = list(self.data.movies.columns.drop(['mID', 'title', 'year']))\n",
    "        self.mid2idx = dict(zip(self.data.movies.mID, list(range(len(self.data.movies)))))\n",
    "        self.uid2idx = dict(zip(self.data.users.uID, list(range(len(self.data.users)))))\n",
    "        self.Mr = self.rating_matrix()\n",
    "        self.Mm = None\n",
    "        self.sim = np.zeros((len(self.allmovies), len(self.allmovies)))\n",
    "\n",
    "    def rating_matrix(self):\n",
    "        \"\"\"\n",
    "        Convert the rating matrix to numpy array of shape (#allusers,#allmovies)\n",
    "        \"\"\"\n",
    "        ind_movie = [self.mid2idx[x] for x in self.data.train.mID]\n",
    "        ind_user = [self.uid2idx[x] for x in self.data.train.uID]\n",
    "        rating_train = list(self.data.train.rating)\n",
    "\n",
    "        return np.array(coo_matrix((rating_train, (ind_user, ind_movie)),\n",
    "                                   shape=(len(self.allusers), len(self.allmovies))).toarray())\n",
    "\n",
    "    def predict_everything_to_3(self):\n",
    "        \"\"\"\n",
    "        Predict everything to 3 for the test data\n",
    "        \"\"\"\n",
    "        return np.ones(len(self.data.test)) * 3\n",
    "\n",
    "    def predict_to_user_average(self):\n",
    "        \"\"\"\n",
    "        Predict to average rating for the user.\n",
    "        Returns numpy array of shape (#users,)\n",
    "        \"\"\"\n",
    "        user_averages = np.zeros(len(self.data.users))\n",
    "        for i, uid in enumerate(self.data.users.uID):\n",
    "            user_ratings = self.Mr[self.uid2idx[uid], :]\n",
    "            num_rated = user_ratings.sum()\n",
    "            if num_rated > 0:\n",
    "                user_movieset = self.Mr[self.uid2idx[uid], :] > 0\n",
    "                user_averages[i] = user_ratings.sum() / user_movieset.sum()\n",
    "            else:\n",
    "                user_averages[i] = 3\n",
    "\n",
    "        # Now map test users to their averages\n",
    "        test_predictions = np.zeros(len(self.data.test))\n",
    "        for i, uid in enumerate(self.data.test.uID):\n",
    "            user_idx = self.uid2idx[uid]\n",
    "            test_predictions[i] = user_averages[user_idx]\n",
    "\n",
    "        return test_predictions\n",
    "\n",
    "    def predict_from_sim(self, uid, mid):\n",
    "        \"\"\"\n",
    "        Predict a user rating on a movie given userID and movieID\n",
    "        \"\"\"\n",
    "        user_idx = self.uid2idx[uid]\n",
    "        movie_idx = self.mid2idx[mid]\n",
    "        user_ratings = self.Mr[user_idx]\n",
    "        movie_sim = self.sim[movie_idx]\n",
    "\n",
    "        user_average = 3\n",
    "\n",
    "        unweighted_ratings = user_ratings @ movie_sim\n",
    "        rated_movies = user_ratings > 0\n",
    "        weighting = np.dot(movie_sim, rated_movies)\n",
    "        if weighting == 0:\n",
    "            num_rated = user_ratings.sum()\n",
    "            if num_rated > 0:\n",
    "                user_movieset = user_ratings > 0\n",
    "                user_average = num_rated / user_movieset.sum()\n",
    "\n",
    "            user_pred = user_average\n",
    "        else:\n",
    "            user_pred = unweighted_ratings / weighting\n",
    "\n",
    "        return user_pred\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict ratings in the test data. Returns predicted rating in a numpy array of size (# of rows in testdata,)\n",
    "        \"\"\"\n",
    "        predicted_ratings = np.zeros(len(self.data.test))\n",
    "        for i in range(len(self.data.test)):\n",
    "            uid = self.data.test.uID[i]\n",
    "            mid = self.data.test.mID[i]\n",
    "            predicted_ratings[i] = self.predict_from_sim(uid, mid)\n",
    "        return predicted_ratings\n",
    "\n",
    "    def rmse(self, yp):\n",
    "        yp[np.isnan(yp)] = 3  #In case there is nan values in prediction, it will impute to 3.\n",
    "        yt = np.array(self.data.test.rating)\n",
    "        return np.sqrt(((yt - yp) ** 2).mean())\n",
    "\n",
    "\n",
    "class ContentBased(RecSys):\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "        self.data = data\n",
    "        self.Mm = self.calc_movie_feature_matrix()\n",
    "\n",
    "    def calc_movie_feature_matrix(self):\n",
    "        \"\"\"\n",
    "        Create movie feature matrix in a numpy array of shape (#allmovies, #genres)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "\n",
    "        return np.asarray(self.data.movies[self.data.movies.columns[3:]])\n",
    "\n",
    "    def calc_item_item_similarity(self):\n",
    "        # item-item similarity using Jaccard similarity\n",
    "        # Method 2: Sparse implementation\n",
    "        Mm_sparse = csr_matrix(self.Mm, dtype=np.float32)\n",
    "        # Calculate intersection matrix\n",
    "        intersection = Mm_sparse @ Mm_sparse.T\n",
    "        # Get movie sizes (number of genres)\n",
    "        movie_sizes = np.array(Mm_sparse.sum(axis=1)).flatten()\n",
    "        # Broadcast to create union matrix\n",
    "        union = movie_sizes[:, None] + movie_sizes[None, :] - intersection.toarray()\n",
    "        # Avoid division by zero\n",
    "        union = np.maximum(union, 1)\n",
    "        # Calculate Jaccard similarity\n",
    "        sparse_sim = intersection.toarray() / union\n",
    "        # Ensure diagonal is 1\n",
    "        np.fill_diagonal(sparse_sim, 1.0)\n",
    "\n",
    "        self.sim = sparse_sim\n",
    "\n",
    "\n",
    "class Collaborative(RecSys):\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "\n",
    "    def calc_item_item_similarity(self, simfunction, *X):\n",
    "        # General function that calculates item-item similarity based on the sim function and data inputed\n",
    "        if len(X) == 0:\n",
    "            self.sim = simfunction()\n",
    "        else:\n",
    "            self.sim = simfunction(X[0])  # *X passes in a tuple format of (X,), to X[0] will be the actual transformed matrix\n",
    "\n",
    "    def cossim(self):\n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using cosine similarity (values from 0 to 1) on utility matrix\n",
    "        Returns a cosine similarity matrix of size (#all movies, #all movies)\n",
    "        \"\"\"\n",
    "        # Return a sim matrix by calculating item-item similarity for all pairs of items using Jaccard similarity\n",
    "        # Cosine Similarity: C(A, B) = (A.B) / (||A||.||B||)\n",
    "\n",
    "        #####\n",
    "        # Method 1 - using dense matrix (including centering and normalisation)\n",
    "        Xd = self.Mr.copy().astype(np.float64)     #(users, movies)\n",
    "        # calculate user averages\n",
    "        user_means = np.zeros(Xd.shape[0])\n",
    "        for i in range(Xd.shape[0]):\n",
    "            rated_movies = Xd[i,:] > 0\n",
    "            if rated_movies.sum() > 0:\n",
    "                user_means[i] = Xd[i,rated_movies].mean()\n",
    "            else:\n",
    "                user_means[i] = 3.0\n",
    "        # replace 0s with user averages\n",
    "        for i in range(Xd.shape[0]):\n",
    "            zero_mask = Xd[i,:] == 0\n",
    "            Xd[i,zero_mask] = user_means[i]\n",
    "        # Centre the data\n",
    "        Xd = Xd - user_means[:,np.newaxis]  # converts user means to column vector of shape (users, 1) before centering\n",
    "        # Transpose to get movies as rows and users as columns\n",
    "        Xd = Xd.T     #(movies, users)\n",
    "        # Normalise the data\n",
    "        norms = np.linalg.norm(Xd, axis=1, keepdims=True)\n",
    "        norms = np.maximum(norms, 1e-10)  # Avoid divide by zero\n",
    "        Xd_norm = Xd / norms\n",
    "        # Calc simularity matrix\n",
    "        sim_dense = Xd_norm @ Xd_norm.T     #Cosine similarity = (A.B) / (||A||.||B||)\n",
    "        # Rescale to be 0~1\n",
    "        sim_dense = (sim_dense + 1) / 2\n",
    "        # Handle NaNs and ensure diagonal is 1\n",
    "        sim_dense = np.nan_to_num(sim_dense, nan=0.5)\n",
    "        np.fill_diagonal(sim_dense, 1.0)\n",
    "\n",
    "        return sim_dense\n",
    "\n",
    "\n",
    "    def jacsim(self, Xr):\n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using jaccard similarity (values from 0 to 1)\n",
    "        Xr is the transformed rating matrix. Shape: (users, movies)\n",
    "        \"\"\"\n",
    "        n = Xr.shape[1]  # Number of movies\n",
    "        maxr = int(Xr.max())  # Maximum rating value\n",
    "\n",
    "        if maxr > 1: # Multi-category case\n",
    "            intersection = np.zeros((n, n)).astype(int)\n",
    "            union = np.zeros((n, n)).astype(int)\n",
    "\n",
    "            for i in range(1, maxr + 1): # intersections and unions for each rating level\n",
    "                rating_level = (Xr == i).astype(int)\n",
    "                csr = csr_matrix(rating_level)\n",
    "                # Intersection for this rating level\n",
    "                level_intersection = np.array(csr.T.dot(csr).toarray()).astype(int)\n",
    "                intersection += level_intersection\n",
    "                # Union for this rating level (users who gave rating i to either movie)\n",
    "                rowsum = rating_level.sum(axis=0)  # Movies with rating i\n",
    "                level_union = rowsum[:, None] + rowsum[None, :] - level_intersection\n",
    "                union += level_union\n",
    "\n",
    "        else: # Binary case\n",
    "            csr0 = csr_matrix((Xr > 0).astype(int))\n",
    "            intersection = np.array(csr0.T.dot(csr0).toarray()).astype(int)\n",
    "            A = (Xr > 0).astype(bool)\n",
    "            rowsum = A.sum(axis=0)\n",
    "            union = rowsum[:, None] + rowsum[None, :] - intersection\n",
    "\n",
    "        # Calculate Jaccard similarity\n",
    "        union = np.maximum(union, 1)\n",
    "        similarity = intersection.astype(float) / union.astype(float)\n",
    "\n",
    "        # Boundary checks\n",
    "        similarity = np.nan_to_num(similarity, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        np.fill_diagonal(similarity, 1.0)\n",
    "\n",
    "        return similarity\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T17:41:15.111237Z",
     "start_time": "2025-09-24T17:41:14.665109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup rs and sample_rs\n",
    "sample_rs = RecSys(sample_data)\n",
    "rs = RecSys(data)\n",
    "\n",
    "# predict_everything_to_3 in class RecSys\n",
    "sample_yp = sample_rs.predict_everything_to_3()\n",
    "yp = rs.predict_everything_to_3()\n",
    "\n",
    "# build dictionary for comparison of RMSE values of all approaches\n",
    "dict_compare = {}\n",
    "rmse_val_sample = sample_rs.rmse(sample_yp)\n",
    "rmse_val_data = rs.rmse(yp)\n",
    "dict_compare['Baseline 3'] = {'sample rmse':rmse_val_sample, 'data rmse':rmse_val_data}\n",
    "\n",
    "# Sample tests predict_to_user_average in the class RecSys\n",
    "sample_yp = sample_rs.predict_to_user_average()\n",
    "yp = rs.predict_to_user_average()\n",
    "rmse_val_sample = sample_rs.rmse(sample_yp)\n",
    "rmse_val_data = rs.rmse(yp)\n",
    "dict_compare['Baseline User Average'] = {'sample rmse':rmse_val_sample, 'data rmse':rmse_val_data}"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "531bc11d4bb9ad16238bb3c6436cf1de",
     "grade": false,
     "grade_id": "cell-2e517f5f3bb7bc8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": "### Content-Based model"
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f4e132a376edada87d141fbcbabcdf9",
     "grade": false,
     "grade_id": "cell-0fd9bcbcf2e542fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2025-09-24T17:41:22.816422Z",
     "start_time": "2025-09-24T17:41:15.331500Z"
    }
   },
   "source": [
    "cb = ContentBased(data)\n",
    "cb.calc_item_item_similarity()\n",
    "sample_cb = ContentBased(sample_data)\n",
    "sample_cb.calc_item_item_similarity()\n",
    "# Sample tests method predict in the RecSys class\n",
    "sample_yp = sample_cb.predict()\n",
    "sample_rmse = sample_cb.rmse(sample_yp)\n",
    "# predict data\n",
    "yp = cb.predict()\n",
    "rmse = cb.rmse(yp)\n",
    "rmse_val_sample = sample_rs.rmse(sample_yp)\n",
    "rmse_val_data = rs.rmse(yp)\n",
    "dict_compare['Content Based Item-Item'] = {'sample rmse':rmse_val_sample, 'data rmse':rmse_val_data}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44f2a6ef3ef78c7ffa924dd74e309beb",
     "grade": false,
     "grade_id": "cell-563e07a0cadec0db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": "### Collaborative Filtering"
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "724694f71418cc260320e7a8ab1326f9",
     "grade": false,
     "grade_id": "cell-4089ff635a4df681",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2025-09-24T17:42:00.992996Z",
     "start_time": "2025-09-24T17:41:22.864852Z"
    }
   },
   "source": [
    "# Sample tests cossim method in the Collaborative class\n",
    "sample_cf = Collaborative(sample_data)\n",
    "sample_cf.calc_item_item_similarity(sample_cf.cossim)\n",
    "sample_yp = sample_cf.predict()\n",
    "sample_rmse = sample_cf.rmse(sample_yp)\n",
    "\n",
    "cf = Collaborative(data)\n",
    "cf.calc_item_item_similarity(cf.cossim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "\n",
    "rmse_val_sample = sample_rs.rmse(sample_yp)\n",
    "rmse_val_data = rs.rmse(yp)\n",
    "dict_compare['Collaborative Cosine Similarity'] = {'sample rmse':rmse_val_sample, 'data rmse':rmse_val_data}\n",
    "#Mr >= 3\n",
    "Xr = cf.Mr>=3\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "yp = cf.predict()\n",
    "rmse_val_sample = None\n",
    "rmse_val_data = rs.rmse(yp)\n",
    "dict_compare['Jacsim - Rating > 3'] = {'sample rmse':rmse_val_sample, 'data rmse':rmse_val_data}\n",
    "\n",
    "# Mr >= 1\n",
    "Xr = cf.Mr>=1\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "yp = cf.predict()\n",
    "rmse_val_sample = None\n",
    "rmse_val_data = rs.rmse(yp)\n",
    "dict_compare['Jacsim - Rating > 1'] = {'sample rmse':rmse_val_sample, 'data rmse':rmse_val_data}\n",
    "\n",
    "# Jacsim Multiclass\n",
    "Xr = cf.Mr.astype(int)\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "yp = cf.predict()\n",
    "rmse_val_sample = None\n",
    "rmse_val_data = rs.rmse(yp)\n",
    "dict_compare['Jacsim - Multiclass'] = {'sample rmse':rmse_val_sample, 'data rmse':rmse_val_data}\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SECTION 1 - matrix factorization technique(s) to predict the missing ratings from the test data\n",
    "\n",
    "Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE. You should use sklearn library. Make sure that your notebook includes the following:\n",
    "* use's sklearn's non-negative matrix factorization\n",
    "* notebook shows the RMSE with an analysis of what that RMSE means"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T17:42:01.041592Z",
     "start_time": "2025-09-24T17:42:01.034600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RatingsNMF(RecSys):\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "        self.H = None\n",
    "        self.W = None\n",
    "        self.predicted_ratings = None\n",
    "\n",
    "    # This was the original fit_nmf function that I tried, but the results were truly awful.\n",
    "    # I found a mix of issues: the sparsity - NMF not handling zeros well, the loss function may not be stable\n",
    "    def fit_nmf_v1(self,genres=16,max_iter=1000,alpha_W=0.01,alpha_H=0.01, beta_loss=\"kullback-leibler\"):\n",
    "\n",
    "        # 'mu' solver required when using kullback-leibler beta_loss\n",
    "        if beta_loss == 'kullback-leibler':\n",
    "            solver = 'mu'\n",
    "            init = 'nndsvda' # changed from 'nndsvd' due to warning message received\n",
    "        else:\n",
    "            solver = 'cd'\n",
    "            init = 'nndsvd'\n",
    "\n",
    "        nmf_model = NMF(\n",
    "            n_components=genres,\n",
    "            random_state=42,\n",
    "            max_iter=max_iter,\n",
    "            alpha_W=alpha_W,  # No regularization initially\n",
    "            alpha_H=alpha_H,\n",
    "            init=init,\n",
    "            solver=solver,\n",
    "            beta_loss=beta_loss, # from lectures kullback-leibler good where we have many zeros\n",
    "        )\n",
    "        # self.Mr rating matrix is a numpy array of shape (#allusers,#allmovies)\n",
    "        # We meed movies as rows and users as columns\n",
    "        self.W = nmf_model.fit_transform(self.Mr)  # users x genres\n",
    "        self.H = nmf_model.components_   # genres x movies\n",
    "        self.predicted_ratings = self.W @ self.H # users x movies\n",
    "        return\n",
    "\n",
    "    # New version of fit_nmf function that uses the frobenius loss function.\n",
    "    # Plus replacing zeros with user-movie bias\n",
    "    def fit_nmf_v2(self,genres=16,max_iter=1000,alpha_W=0.01,alpha_H=0.01):\n",
    "\n",
    "        matrix_for_nmf = self.Mr.copy().astype(np.float64)\n",
    "\n",
    "        # Calculate user and movie means for non-zero ratings\n",
    "        user_means = np.zeros(matrix_for_nmf.shape[0])\n",
    "        movie_means = np.zeros(matrix_for_nmf.shape[1])\n",
    "\n",
    "        for i in range(matrix_for_nmf.shape[0]):\n",
    "            rated = matrix_for_nmf[i, :] > 0\n",
    "            if rated.sum() > 0:\n",
    "                user_means[i] = matrix_for_nmf[i, rated].mean()\n",
    "            else:\n",
    "                user_means[i] = 3.0\n",
    "\n",
    "        for j in range(matrix_for_nmf.shape[1]):\n",
    "            rated = matrix_for_nmf[:, j] > 0\n",
    "            if rated.sum() > 0:\n",
    "                movie_means[j] = matrix_for_nmf[rated, j].mean()\n",
    "            else:\n",
    "                movie_means[j] = 3.0\n",
    "\n",
    "        # Fill zeros with combined user-movie bias\n",
    "        for i in range(matrix_for_nmf.shape[0]):\n",
    "            for j in range(matrix_for_nmf.shape[1]):\n",
    "                if matrix_for_nmf[i, j] == 0:\n",
    "                    matrix_for_nmf[i, j] = (user_means[i] + movie_means[j]) / 2\n",
    "\n",
    "        # Apply NMF\n",
    "        nmf_model = NMF(\n",
    "            n_components=genres,\n",
    "            random_state=42,\n",
    "            max_iter=max_iter,\n",
    "            alpha_W=alpha_W,\n",
    "            alpha_H=alpha_H,\n",
    "            init='nndsvd',\n",
    "            solver='cd',\n",
    "            beta_loss='frobenius'\n",
    "        )\n",
    "\n",
    "        self.W = nmf_model.fit_transform(matrix_for_nmf)\n",
    "        self.H = nmf_model.components_\n",
    "        self.predicted_ratings = self.W @ self.H\n",
    "        return\n",
    "\n",
    "    def predict(self, test_data=None):\n",
    "        \"\"\"\n",
    "        Predict ratings using the fitted NMF model\n",
    "        \"\"\"\n",
    "        if self.predicted_ratings is None:\n",
    "            raise ValueError(\"Model must be fitted first. Call fit_nmf() before predict()\")\n",
    "        if test_data is None:\n",
    "            test_data = self.data.test\n",
    "\n",
    "        test_pairs = test_data[['uID', 'mID']].values\n",
    "        user_indices = [self.uid2idx[uid] for uid in test_pairs[:, 0].astype(int)]\n",
    "        movie_indices = [self.mid2idx[mid] for mid in test_pairs[:, 1].astype(int)]\n",
    "        predictions = self.predicted_ratings[user_indices, movie_indices]\n",
    "        predictions = np.clip(predictions, 1.0, 5.0)\n",
    "        return predictions\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T17:42:31.989006Z",
     "start_time": "2025-09-24T17:42:01.048061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# instantiate class for NMF exploration\n",
    "nmf_r = RatingsNMF(data)\n",
    "# Latent Dimension = genres\n",
    "genres = 16\n",
    "# fit the model and add the results to self.W, self.H and self.predicted_ratings\n",
    "nmf_r.fit_nmf_v1(genres=genres)\n",
    "# predict and find the rmse\n",
    "yp = nmf_r.predict(data.test)\n",
    "rmse_val_sample = None\n",
    "rmse_val_data = rs.rmse(yp)\n",
    "dict_compare['NMF v1'] = {'sample rmse':rmse_val_sample, 'data rmse':rmse_val_data}"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T17:43:21.268201Z",
     "start_time": "2025-09-24T17:43:09.889649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fit the model and add the results to self.W, self.H and self.predicted_ratings\n",
    "nmf_r.fit_nmf_v2(genres=genres, alpha_W = 0.05, alpha_H = 0.05, max_iter=2000)\n",
    "# predict and find the rmse\n",
    "yp = nmf_r.predict(data.test)\n",
    "rmse_val_sample = None\n",
    "rmse_val_data = rs.rmse(yp)\n",
    "dict_compare['NMF v2'] = {'sample rmse':rmse_val_sample, 'data rmse':rmse_val_data}\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T17:43:24.398560Z",
     "start_time": "2025-09-24T17:43:24.393935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_compare = pd.DataFrame(dict_compare).T.reset_index()\n",
    "df_compare.columns.name = None  # Remove the column name 'index'\n",
    "df_compare = df_compare.rename(columns={'index': 'Method'})\n",
    "display(df_compare)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            Method  sample rmse  data rmse\n",
       "0                       Baseline 3     1.264278   1.258551\n",
       "1            Baseline User Average     1.142960   1.035291\n",
       "2          Content Based Item-Item     1.196609   1.012503\n",
       "3  Collaborative Cosine Similarity     1.142693   1.026308\n",
       "4              Jacsim - Rating > 3          NaN   0.981950\n",
       "5              Jacsim - Rating > 1          NaN   0.991354\n",
       "6              Jacsim - Multiclass          NaN   0.951656\n",
       "7                           NMF v1          NaN   2.594395\n",
       "8                           NMF v2          NaN   0.953741"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>sample rmse</th>\n",
       "      <th>data rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline 3</td>\n",
       "      <td>1.264278</td>\n",
       "      <td>1.258551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline User Average</td>\n",
       "      <td>1.142960</td>\n",
       "      <td>1.035291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Content Based Item-Item</td>\n",
       "      <td>1.196609</td>\n",
       "      <td>1.012503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Collaborative Cosine Similarity</td>\n",
       "      <td>1.142693</td>\n",
       "      <td>1.026308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jacsim - Rating &gt; 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jacsim - Rating &gt; 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jacsim - Multiclass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.951656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NMF v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.594395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NMF v2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SECTION 2 - Discuss the Results\n",
    "\n",
    "Discuss the results and why they did not work well compared to simple baseline or similarity-based methods we’ve done in Module 3. Can you suggest a way(s) to fix it?\n",
    "\n",
    "#### Original attempt - fit_nmf_v1 in class RatingsNMF\n",
    "This first attempt yielded an RMSE that is equivalent to chance and far worse than all previous methods tried. I discovered several issues:\n",
    "1) The sparsity of the data - NMF not handling zeros well\n",
    "2) The loss function may not be stable (I only introduced kullback-leibler based on what we heard in the lectures in an attempt to deal with the sparsity issue, but it did not help)\n",
    "\n",
    "NMF struggles with highly sparse data because:\n",
    "- It tries to find latent factors that explain all observed ratings\n",
    "- Sparse data provides insufficient information for meaningful factorization\n",
    "- The algorithm may converge to poor local minima\n",
    "\n",
    "I tried replacing all the zeros with minimal values (0.01), but this did not improve the RMSE at all.\n",
    "\n",
    "#### Final version Fixing the Issues - fit_nmf_v2 in class RatingsNMF\n",
    "Remembering the discussion in the lectures and the user average computation used in Item-Item similarity, I tried replacing all the zeros with the average of the user and movie biases. For this function, I used both user-average and movie-average to compute a combined user-movie bias, which was then used to replace all zeros.\n",
    "Additionally, I played with the parameters:\n",
    "1) Froebenius loss function\n",
    "2) Regularization parameters - to reduce the iterations required\n",
    "3) Max iterations - to limit the warnings received\n",
    "\n",
    "This second attempt yielded a much better RMSE, almost identical to the performance of Jaccard Multi Class Similarity.\n",
    "\n",
    "Essentially this is a hybrid solution, imputing averages to address the problem of sparsity. It seems to be a good fix!\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
